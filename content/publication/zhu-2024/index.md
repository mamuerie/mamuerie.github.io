---
title: Natural Scenes Reveal Diverse Representations of 2D and 3D Body Pose in the
  Human Brain
authors:
- Hongru Zhu
- Yijun Ge
- Alexander Bratch
- Alan Yuille
- Kendrick Kay
- Daniel Kersten
date: '2024-01-01T00:00:00'
publishDate: '2024-12-24T10:27:57.618602Z'
publication_types:
- article-journal
doi: 10.1073/pnas.2317707121
abstract: Human pose, defined as the spatial relationships between body parts, carries
  instrumental information supporting the understanding of motion and action of a
  person. A substantial body of previous work has identified cortical areas responsive
  to images of bodies and different body parts. However, the neural basis underlying
  the visual perception of body part relationships has received less attention. To
  broaden our understanding of body perception, we analyzed high-resolution fMRI responses
  to a wide range of poses from over 4,000 complex natural scenes. Using ground-truth
  annotations and an application of three-dimensional (3D) pose reconstruction algorithms,
  we compared similarity patterns of cortical activity with similarity patterns built
  from human pose models with different levels of depth availability and viewpoint
  dependency. Targeting the challenge of explaining variance in complex natural image
  responses with interpretable models, we achieved statistically significant correlations
  between pose models and cortical activity patterns (though performance levels are
  substantially lower than the noise ceiling). We found that the 3D view-independent
  pose model, compared with two-dimensional models, better captures the activation
  from distinct cortical areas, including the right posterior superior temporal sulcus
  (pSTS). These areas, together with other pose-selective regions in the LOTC, form
  a broader, distributed cortical network with greater view-tolerance in more anterior
  patches. We interpret these findings in light of the computational complexity of
  natural body images, the wide range of visual tasks supported by pose structures,
  and possible shared principles for view-invariant processing between articulated
  objects and ordinary, rigid objects.
---
